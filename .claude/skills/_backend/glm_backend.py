"""
GLM API Backend Server
ä¸ºClaude Code Skillsæä¾›GLM-4.6æ¨¡å‹è°ƒç”¨æœåŠ¡
"""

from flask import Flask, request, jsonify
from zhipuai import ZhipuAI
import os
import logging
from datetime import datetime

app = Flask(__name__)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–GLMå®¢æˆ·ç«¯
API_KEY = os.getenv("GLM_API_KEY")
if not API_KEY:
    print("âŒ é”™è¯¯ï¼šæœªè®¾ç½® GLM_API_KEY ç¯å¢ƒå˜é‡")
    print("\nè¯·è®¾ç½®æ‚¨çš„GLM API Key:")
    print("export GLM_API_KEY='your-api-key'")
    print("\nè·å–API Key: https://open.bigmodel.cn/")

client = ZhipuAI(api_key=API_KEY) if API_KEY else None

# ç»Ÿè®¡ä¿¡æ¯
stats = {
    "total_requests": 0,
    "total_tokens": 0,
    "total_cost": 0.0,
    "start_time": datetime.now()
}

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        "status": "healthy",
        "model": "glm-4.6",
        "api_key_set": bool(API_KEY),
        "stats": stats
    })

@app.route('/api/generate', methods=['POST'])
def generate_text():
    """è°ƒç”¨GLM-4.6ç”Ÿæˆæ–‡æœ¬"""
    if not client:
        return jsonify({
            "success": False,
            "error": "GLM API Keyæœªé…ç½®"
        }), 400

    try:
        data = request.json
        prompt = data.get("prompt", "")
        system_prompt = data.get("system", "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œåŠ©æ‰‹")
        max_tokens = data.get("max_tokens", 2000)
        model = data.get("model", "glm-4.6")
        temperature = data.get("temperature", 0.7)

        if not prompt:
            return jsonify({
                "success": False,
                "error": "ç¼ºå°‘promptå‚æ•°"
            }), 400

        logger.info(f"æ”¶åˆ°è¯·æ±‚ï¼š{prompt[:50]}...")

        # è°ƒç”¨GLM API
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": prompt}
            ],
            max_tokens=max_tokens,
            temperature=temperature
        )

        content = response.choices[0].message.content
        usage = response.usage

        # æ›´æ–°ç»Ÿè®¡
        stats["total_requests"] += 1
        stats["total_tokens"] += usage.total_tokens

        # è®¡ç®—æˆæœ¬ï¼ˆGLM-4.6ä»·æ ¼ï¼‰
        cost_per_1k = {
            "glm-4.6": 0.005,
            "glm-4.5": 0.0014,
            "glm-3-turbo": 0.0005
        }
        cost = (usage.total_tokens / 1000) * cost_per_1k.get(model, 0.005)
        stats["total_cost"] += cost

        logger.info(f"ç”ŸæˆæˆåŠŸï¼Œä½¿ç”¨ {usage.total_tokens} tokens")

        return jsonify({
            "success": True,
            "content": content,
            "model": model,
            "usage": {
                "prompt_tokens": usage.prompt_tokens,
                "completion_tokens": usage.completion_tokens,
                "total_tokens": usage.total_tokens
            },
            "cost": cost,
            "timestamp": datetime.now().isoformat()
        })

    except Exception as e:
        logger.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/analyze', methods=['POST'])
def analyze_text():
    """æ–‡æœ¬åˆ†æ"""
    if not client:
        return jsonify({
            "success": False,
            "error": "GLM API Keyæœªé…ç½®"
        }), 400

    try:
        data = request.json
        text = data.get("text", "")
        analysis_type = data.get("type", "summary")

        prompts = {
            "summary": "è¯·æ€»ç»“ä»¥ä¸‹æ–‡æœ¬çš„ä¸»è¦å†…å®¹ï¼š",
            "keywords": "è¯·æå–ä»¥ä¸‹æ–‡æœ¬çš„å…³é”®è¯ï¼š",
            "sentiment": "è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼š",
            "style": "è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„å†™ä½œé£æ ¼ï¼š"
        }

        prompt = prompts.get(analysis_type, prompts["summary"]) + f"\n\n{text}"

        response = client.chat.completions.create(
            model="glm-4.5",  # åˆ†æä½¿ç”¨è¾ƒä¾¿å®œçš„æ¨¡å‹
            messages=[
                {"role": "user", "content": prompt}
            ]
        )

        return jsonify({
            "success": True,
            "analysis": response.choices[0].message.content,
            "type": analysis_type
        })

    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/stats', methods=['GET'])
def get_stats():
    """è·å–ä½¿ç”¨ç»Ÿè®¡"""
    runtime = datetime.now() - stats["start_time"]
    return jsonify({
        "total_requests": stats["total_requests"],
        "total_tokens": stats["total_tokens"],
        "total_cost": stats["total_cost"],
        "runtime_hours": runtime.total_seconds() / 3600,
        "avg_cost_per_request": stats["total_cost"] / max(1, stats["total_requests"])
    })

if __name__ == '__main__':
    if not API_KEY:
        print("\nâš ï¸  è­¦å‘Šï¼šæœªæ£€æµ‹åˆ°GLM_API_KEY")
        print("æœåŠ¡å°†å¯åŠ¨ä½†æ— æ³•è°ƒç”¨GLM API\n")

    print("ğŸš€ GLM API Backend Server å¯åŠ¨ä¸­...")
    print("ğŸ“ æœåŠ¡åœ°å€ï¼šhttp://localhost:5000")
    print("ğŸ“Š å¥åº·æ£€æŸ¥ï¼šhttp://localhost:5000/health")
    print("ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯ï¼šhttp://localhost:5000/stats")
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡\n")

    app.run(host='0.0.0.0', port=5000, debug=True)